{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/vinicius/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "import seaborn as sns\n",
    "nltk.download('rslp')\n",
    "from nltk.stem import RSLPStemmer\n",
    "import heapq as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../lab3/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the index to a csv file with the given name\n",
    "def save_index(index, filename):    \n",
    "    words = []\n",
    "    docs = []\n",
    "    for key in index:\n",
    "        words.append(key)\n",
    "        docs.append(str(index[key]))\n",
    "    d = {'words': words, 'docs': docs}\n",
    "    df = pd.DataFrame(d, columns = [\"words\", \"docs\"])\n",
    "    df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens from a document\n",
    "def parse(doc):\n",
    "    words = ''.join(str(v) for v in doc).lower()\n",
    "    return RegexpTokenizer(r'[A-zÀ-ú\\d]{,}').tokenize(words)\n",
    "\n",
    "#build an index for a collection of documents\n",
    "def build_index(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    for text in docs.texto:\n",
    "        n +=1\n",
    "        tokens = list(set(parse(text)))\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                index[token].append(n)\n",
    "            else:\n",
    "                index[token] = [n]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_index(data)\n",
    "save_index(index, \"index.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an index for a collection of documents\n",
    "def build_index_with_frequency(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    for text in docs.texto:\n",
    "        n +=1\n",
    "        tokens = parse(text)\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                hasDoc = False\n",
    "                for i in range(len(index[token])):\n",
    "                    tup = index[token][i]\n",
    "                    if (tup[0] == n):\n",
    "                        index[token][i] = (n, tup[1] + 1)\n",
    "                        hasDoc = True\n",
    "                if (not hasDoc):\n",
    "                    index[token].append((n,1))\n",
    "            else:\n",
    "                index[token] = [(n,1)]\n",
    "    return index\n",
    "#build_index_with_frequency(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[189, 175, 1, 113, 103, 24, 198, 187, 166, 14]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def document_at_time_retrieval(query, index, n_results):\n",
    "    inverted_lists = []\n",
    "    results = []\n",
    "    \n",
    "    for term in query.split():\n",
    "        inverted_lists.append(index[term])\n",
    "    \n",
    "    documents = []\n",
    "    for key in index:\n",
    "        il = index[key]\n",
    "        for doc in il:\n",
    "            documents.append(doc[0])\n",
    "    documents = list(set(documents))\n",
    "    \n",
    "    for doc in documents:\n",
    "        score = 0\n",
    "        for il in inverted_lists:\n",
    "            for d in il:\n",
    "                if (d[0] == doc):\n",
    "                    score += d[1]\n",
    "        results.append((score, doc))\n",
    "    \n",
    "    results = sorted(results, reverse=True)\n",
    "    r = []\n",
    "    for i in range(n_results):\n",
    "        r.append(results[i][1])\n",
    "    return r\n",
    "            \n",
    "document_at_time_retrieval(\"jogo belo\", build_index_with_frequency(data), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[189, 175, 1, 113, 103, 24, 198, 187, 166, 14]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def term_at_time_retrieval(query, index, n_results):\n",
    "    doc_scores = {}\n",
    "    inverted_lists = []\n",
    "    results = []\n",
    "    \n",
    "    for term in query.split():\n",
    "        inverted_lists.append(index[term])\n",
    "        for il in inverted_lists:\n",
    "            for doc in il:\n",
    "                doc_id = doc[0]\n",
    "                doc_freq = doc[1]\n",
    "                if (doc_id in doc_scores):\n",
    "                    doc_scores[doc_id] += doc_freq\n",
    "                else:\n",
    "                    doc_scores[doc_id] = doc_freq\n",
    "    \n",
    "    for doc in doc_scores:\n",
    "        results.append((doc_scores[doc], doc))\n",
    "    \n",
    "    results = sorted(results, reverse=True)\n",
    "    r = []\n",
    "    for i in range(n_results):\n",
    "        r.append(results[i][1])\n",
    "    return r  \n",
    "document_at_time_retrieval(\"belo jogo\", build_index_with_frequency(data), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189, 175, 1, 113, 103, 24, 198, 187, 166, 14], [189, 193, 127, 9, 4, 196, 191, 190, 183, 177], [195, 197, 176, 200, 187, 12, 7, 191, 189, 198], [144, 107, 67, 191, 180, 126, 84, 200, 198, 197], [157, 107, 153, 178, 141, 96, 87, 26, 23, 186]]\n",
      "[[189, 175, 1, 113, 103, 24, 198, 187, 166, 14], [189, 193, 127, 9, 4, 196, 191, 190, 183, 177], [195, 197, 176, 200, 187, 12, 7, 191, 189, 198], [144, 107, 67, 191, 180, 126, 84, 200, 198, 197], [157, 107, 153, 178, 141, 96, 87, 26, 23, 186]]\n"
     ]
    }
   ],
   "source": [
    "query_terms = [\"jogo\", \"partida\", \"futebol\", \"campo\", \"universidade\"]\n",
    "document_at_time_results = []\n",
    "term_at_time_results = []\n",
    "index = build_index_with_frequency(data)\n",
    "for term in query_terms:\n",
    "    document_at_time_results.append(document_at_time_retrieval(term, index, 10))\n",
    "    term_at_time_results.append(term_at_time_retrieval(term, index, 10))\n",
    "\n",
    "\n",
    "print(document_at_time_results)\n",
    "print(term_at_time_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver nos resultados acima que obetemos os mesmos resultados oriundos de algoritmos distintos, isso nos dá uma boa confiança na corretude das implementações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comparar tempo médio de execução e uso de memória dos algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_at_time_conj_retrieval(query, index, n_results):\n",
    "    inverted_lists = []\n",
    "    results = []\n",
    "    for term in query.split():\n",
    "        inverted_lists.append(index[term])\n",
    "        \n",
    "    queries = [item for sublist in inverted_lists for item in sublist]\n",
    "    queries.sort()\n",
    "    print(queries)\n",
    "    for i in range(len(queries)):\n",
    "        score = 0\n",
    "        d = queries.pop()\n",
    "        repeat = 1\n",
    "        for ind in queries:\n",
    "            if ind[0] == d[0]:\n",
    "                score += ind[1]\n",
    "                repeat += 1\n",
    "        if score != 0 and repeat == len(inverted_lists):\n",
    "            doc_score += d[1]\n",
    "            results.append((score, d[0]))\n",
    "    \n",
    "    results = sorted(results, reverse=True)\n",
    "    r = []\n",
    "    print(results)\n",
    "    for i in range(n_results):\n",
    "        r.append(results[i][0])\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 75, 12, 13, 3, 28, 98, 17, 16, 15], [89, 19, 17, 6, 3, 16, 91, 90, 13, 77], [19, 97, 76, 20, 87, 2, 7, 91, 19, 98], [14, 7, 6, 91, 80, 16, 8, 1, 18, 197], [17, 7, 143, 78, 161, 66, 97, 67, 83, 16]]\n"
     ]
    }
   ],
   "source": [
    "and_query_terms = [\"partida de futebol\", \"governo federal\", \"o presidente\", \"universidade federal\", \"as vias\"]\n",
    "and_results = []\n",
    "for query in and_query_terms:\n",
    "    and_results.append(doc_at_time_conj_retrieval(term, index, 10))\n",
    "print(and_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
