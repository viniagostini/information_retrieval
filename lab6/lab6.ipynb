{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/vinicius/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "import seaborn as sns\n",
    "nltk.download('rslp')\n",
    "from nltk.stem import RSLPStemmer\n",
    "import heapq as hp\n",
    "from collections import Counter,OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reconstruir o índice considerando o conjunto de dados que indicamos. Esses são os dados coletados por Bernardi e os estaremos usando para facilitar a correção da atividade. Se você já estiver usando esses dados não precisa reconstruir o índice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens from a document\n",
    "def parse(doc):\n",
    "    words = ''.join(str(v) for v in doc).lower()\n",
    "    return RegexpTokenizer(r'[A-zÀ-ú\\d]{4,}').tokenize(words)\n",
    "\n",
    "# produces: term:[(doc, frequency)]\n",
    "#build an index for a collection of documents\n",
    "def build_index_with_frequency(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    for text in docs.text:\n",
    "        n +=1\n",
    "        tokens = parse(text)\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                hasDoc = False\n",
    "                for i in range(len(index[token])):\n",
    "                    tup = index[token][i]\n",
    "                    if (tup[0] == n):\n",
    "                        index[token][i] = (n, tup[1] + 1)\n",
    "                        hasDoc = True\n",
    "                if (not hasDoc):\n",
    "                    index[token].append((n,1))\n",
    "            else:\n",
    "                index[token] = [(n,1)]\n",
    "    return index\n",
    "index = build_index_with_frequency(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refinar o índice invertido de forma a também incluir o IDF (inverse document frequency) de cada termo do dicionário; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces: term:[(doc, frequency), idf]\n",
    "#build an index for a collection of documents\n",
    "def build_index_with_frequency_and_idf(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    M = len(docs)\n",
    "    for text in docs.text:\n",
    "        n +=1\n",
    "        tokens = parse(text)\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                hasDoc = False\n",
    "                for i in range(len(index[token])):\n",
    "                    tup = index[token][i]\n",
    "                    if (tup[0] == n):\n",
    "                        index[token][i] = (n, tup[1] + 1)\n",
    "                        hasDoc = True\n",
    "                if (not hasDoc):\n",
    "                    index[token].append((n,1))\n",
    "            else:\n",
    "                index[token] = [(n,1)]\n",
    "    \n",
    "    for elem in index:\n",
    "        k = len(index[elem])\n",
    "        idf = math.log((M+1)/k)\n",
    "        index[elem].append(idf)\n",
    "    return index\n",
    "\n",
    "index = build_index_with_frequency_and_idf(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
