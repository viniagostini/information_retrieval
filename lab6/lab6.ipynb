{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/vinicius/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "import seaborn as sns\n",
    "nltk.download('rslp')\n",
    "from nltk.stem import RSLPStemmer\n",
    "import heapq as hp\n",
    "from collections import Counter,OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reconstruir o índice considerando o conjunto de dados que indicamos. Esses são os dados coletados por Bernardi e os estaremos usando para facilitar a correção da atividade. Se você já estiver usando esses dados não precisa reconstruir o índice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens from a document\n",
    "def parse(doc):\n",
    "    words = ''.join(str(v) for v in doc).lower()\n",
    "    return RegexpTokenizer(r'[A-zÀ-ú\\d]{4,}').tokenize(words)\n",
    "\n",
    "# produces: term:[(doc, frequency)]\n",
    "#build an index for a collection of documents\n",
    "def build_index_with_frequency(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    for text in docs.text:\n",
    "        n +=1\n",
    "        tokens = parse(text)\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                hasDoc = False\n",
    "                for i in range(len(index[token])):\n",
    "                    tup = index[token][i]\n",
    "                    if (tup[0] == n):\n",
    "                        index[token][i] = (n, tup[1] + 1)\n",
    "                        hasDoc = True\n",
    "                if (not hasDoc):\n",
    "                    index[token].append((n,1))\n",
    "            else:\n",
    "                index[token] = [(n,1)]\n",
    "    return index\n",
    "index = build_index_with_frequency(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Refinar o índice invertido de forma a também incluir o IDF (inverse document frequency) de cada termo do dicionário; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces: term:[(doc, frequency), idf]\n",
    "#build an index for a collection of documents\n",
    "def build_index_with_frequency_and_idf(docs):\n",
    "    index = {}\n",
    "    n = 0\n",
    "    M = len(docs)\n",
    "    for text in docs.text:\n",
    "        n +=1\n",
    "        tokens = parse(text)\n",
    "        for token in tokens:\n",
    "            if (token in index):\n",
    "                hasDoc = False\n",
    "                for i in range(len(index[token])):\n",
    "                    tup = index[token][i]\n",
    "                    if (tup[0] == n):\n",
    "                        index[token][i] = (n, tup[1] + 1)\n",
    "                        hasDoc = True\n",
    "                if (not hasDoc):\n",
    "                    index[token].append((n,1))\n",
    "            else:\n",
    "                index[token] = [(n,1)]\n",
    "    \n",
    "    for elem in index:\n",
    "        k = len(index[elem])\n",
    "        idf = math.log((M+1)/k)\n",
    "        index[elem].append(idf)\n",
    "    return index\n",
    "\n",
    "index = build_index_with_frequency_and_idf(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementar as seguintes versões do modelo vetorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representação binária:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_rep(query, doc):\n",
    "    score = 0\n",
    "    query_t = query.split()\n",
    "    doc_t = doc.split()\n",
    "    for t in query_t:\n",
    "        score += (t in doc_t)\n",
    "    return score\n",
    "#for el in data.text:\n",
    "#    print(binary_vsm(\"deputado federal\", el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(query, doc):\n",
    "    score = 0\n",
    "    doc_t = doc.split()\n",
    "    query_t = query.split()\n",
    "    for t in query_t:\n",
    "        score += doc_t.count(t)\n",
    "    return score\n",
    "#for el in data.text:\n",
    "#    print(tf(\"deputado federal\", el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(query, doc, index):\n",
    "    score = 0\n",
    "    doc_t = doc.split()\n",
    "    query_t = query.split()\n",
    "    for t in query_t:\n",
    "        count = doc_t.count(t)\n",
    "        if t in index:\n",
    "            score += count * index[t][-1]\n",
    "    return round(score, 2)\n",
    "#index = build_index_with_frequency_and_idf(data)\n",
    "#for el in data.text:\n",
    "#    print(tfidf(\"deputado federal\", el, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(query, doc, index):\n",
    "    k = 1\n",
    "    M = len(data)\n",
    "    doc_t = doc.split()\n",
    "    query_t = query.split()\n",
    "    words = list(set(doc_t) & set(query_t))\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        cwq = query_t.count(word)\n",
    "        cwd = doc_t.count(word)\n",
    "        dfw = len(index[word][:-1])\n",
    "        y = ((k+1)*cwd)/(cwd+k)\n",
    "        score += cwq * y * math.log((M+1)/dfw)\n",
    "    return score\n",
    "#index = build_index_with_frequency_and_idf(data)\n",
    "#for el in data.text:\n",
    "#    print(bm25(\"deputado federal\", el, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Execute os algoritmos separadamente em 3 consultas de sua escolha e retorne os top-5 documentos mais similares à cada consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Binary</th>\n",
       "      <th>TF</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>campeonato brasileiro</td>\n",
       "      <td>[(2, 54), (1, 237), (1, 224), (1, 223), (1, 222)]</td>\n",
       "      <td>[(6, 54), (4, 163), (4, 104), (4, 41), (3, 209)]</td>\n",
       "      <td>[(15.73, 54), (6.06, 163), (6.06, 104), (6.06,...</td>\n",
       "      <td>[(7.86574377189595, 54), (3.7297014486341915, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ministério público</td>\n",
       "      <td>[(2, 216), (2, 208), (1, 246), (1, 245), (1, 2...</td>\n",
       "      <td>[(10, 196), (4, 216), (4, 198), (4, 109), (4, ...</td>\n",
       "      <td>[(12.45, 196), (5.49, 216), (5.28, 123), (4.98...</td>\n",
       "      <td>[(3.6274530004379706, 216), (3.005055601014875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jair bolsonaro</td>\n",
       "      <td>[(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...</td>\n",
       "      <td>[(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...</td>\n",
       "      <td>[(0.0, 248), (0.0, 247), (0.0, 246), (0.0, 245...</td>\n",
       "      <td>[(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Query                                             Binary  \\\n",
       "0  campeonato brasileiro  [(2, 54), (1, 237), (1, 224), (1, 223), (1, 222)]   \n",
       "1     ministério público  [(2, 216), (2, 208), (1, 246), (1, 245), (1, 2...   \n",
       "2         jair bolsonaro  [(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...   \n",
       "\n",
       "                                                  TF  \\\n",
       "0   [(6, 54), (4, 163), (4, 104), (4, 41), (3, 209)]   \n",
       "1  [(10, 196), (4, 216), (4, 198), (4, 109), (4, ...   \n",
       "2  [(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...   \n",
       "\n",
       "                                              TF-IDF  \\\n",
       "0  [(15.73, 54), (6.06, 163), (6.06, 104), (6.06,...   \n",
       "1  [(12.45, 196), (5.49, 216), (5.28, 123), (4.98...   \n",
       "2  [(0.0, 248), (0.0, 247), (0.0, 246), (0.0, 245...   \n",
       "\n",
       "                                                BM25  \n",
       "0  [(7.86574377189595, 54), (3.7297014486341915, ...  \n",
       "1  [(3.6274530004379706, 216), (3.005055601014875...  \n",
       "2  [(0, 248), (0, 247), (0, 246), (0, 245), (0, 2...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = ['campeonato brasileiro', 'ministério público', 'jair bolsonaro']\n",
    "def top_5(query, index):\n",
    "    doc_id = 0\n",
    "    bin_res = []\n",
    "    tf_res = []\n",
    "    tdidf_res = []\n",
    "    bm25_res = []\n",
    "    for doc in data.text:\n",
    "        bin_res.append((binary_rep(query, doc), doc_id))\n",
    "        tf_res.append((tf(query, doc), doc_id))\n",
    "        tdidf_res.append((tfidf(query, doc, index), doc_id))\n",
    "        bm25_res.append((bm25(query, doc, index), doc_id))\n",
    "        doc_id += 1\n",
    "    bin_res = sorted(bin_res, reverse=True)\n",
    "    tf_res = sorted(tf_res, reverse=True)\n",
    "    tdidf_res = sorted(tdidf_res, reverse=True)\n",
    "    bm25_res = sorted(bm25_res, reverse=True)\n",
    "    return bin_res[:5], tf_res[:5], tdidf_res[:5], bm25_res[:5]\n",
    "top5_binary = [0,0,0]\n",
    "top5_tf = [0,0,0]\n",
    "top5_tfidf = [0,0,0]\n",
    "top5_bm25 = [0,0,0]\n",
    "for i in range(len(queries)):\n",
    "    q = queries[i]\n",
    "    top5_binary[i], top5_tf[i], top5_tfidf[i], top5_bm25[i] = top_5(q, index)\n",
    "\n",
    "    \n",
    "query_df = pd.DataFrame()\n",
    "\n",
    "query_df['Query'] = queries\n",
    "query_df['Binary'] = top5_binary\n",
    "query_df['TF'] = top5_tf\n",
    "query_df['TF-IDF'] = top5_tfidf\n",
    "query_df['BM25'] = top5_bm25\n",
    "\n",
    "query_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
